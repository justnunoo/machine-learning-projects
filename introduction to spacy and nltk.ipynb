{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "746dc2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing spacy library\n",
    "import spacy\n",
    "\n",
    "#loading english language into spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa67e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves pizza.\n",
      "The Hulk loves to crush.\n"
     ]
    }
   ],
   "source": [
    "#creating an object to handle the text\n",
    "doc = nlp('Dr. Strange loves pizza. The Hulk loves to crush.')\n",
    "\n",
    "#printing the sentences in the text\n",
    "for sentences in doc.sents:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afdb267b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange\n",
      "loves\n",
      "pizza\n",
      ".\n",
      "The\n",
      "Hulk\n",
      "loves\n",
      "to\n",
      "crush\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#print the individual words and punctuations in the text\n",
    "for sentences in doc.sents:\n",
    "    for words in sentences:\n",
    "        print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d00750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0197bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''The name of the client is kingsley Dawutey. His email address is kingsley@gmail.com. His phone number is 0244487359.'''\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18369d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email is kingsley@gmail.com\n",
      "Phone number is 0244487359\n",
      "[The, name, of, the, client, is, kingsley, Dawutey, ., His, email, address, is, ., His, phone, number, is, .]\n"
     ]
    }
   ],
   "source": [
    "other = []\n",
    "for token in doc:\n",
    "    if token.is_digit:\n",
    "        print(f'Phone number is {token}')\n",
    "    elif token.like_email:\n",
    "        print(f'Email is {token}')\n",
    "    else:\n",
    "        other.append(token)\n",
    "print(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d95032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12126a93",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "(1) Think stats is a free book to study statistics (https://greenteapress.com/thinkstats2/thinkstats2.pdf)\n",
    "\n",
    "This book has references to many websites from where you can download free datasets. You are an NLP engineer working for some company and you want to collect all dataset websites from this book. To keep exercise simple you are given a paragraph from this book and you want to grab all urls from this paragraph using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a293a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2979fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Look for data to help you address the question.\n",
      "Governments are good\n",
      "sources because data from public research is often freely available.\n",
      "Good\n",
      "places to start include http://www.data.gov/, and http://www.science.\n",
      "\n",
      "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
      "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
      "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "for sentences in doc.sents:\n",
    "    print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c763e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [url for url in doc if url.like_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5df508ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[http://www.data.gov/,\n",
       " http://www.science,\n",
       " http://data.gov.uk/.,\n",
       " http://www3.norc.org/gss+website/,\n",
       " http://www.europeansocialsurvey.org/.]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a68eb3",
   "metadata": {},
   "source": [
    "(2) Extract all money transaction from below sentence along with currency. Output should be,\n",
    "\n",
    "two $\n",
    "\n",
    "500 €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca9672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfb7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dc6f464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text, doc[token.i+1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13db96c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony\n",
      "gave\n",
      "two\n",
      "$\n",
      "to\n",
      "Peter\n",
      ",\n",
      "Bruce\n",
      "gave\n",
      "500\n",
      "€\n",
      "to\n",
      "Steve\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6022a7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony  |  PROPN  |  Tony\n",
      "gave  |  VERB  |  give\n",
      "two  |  NUM  |  two\n",
      "$  |  SYM  |  $\n",
      "to  |  ADP  |  to\n",
      "Peter  |  PROPN  |  Peter\n",
      ",  |  PUNCT  |  ,\n",
      "Bruce  |  PROPN  |  Bruce\n",
      "gave  |  VERB  |  give\n",
      "500  |  NUM  |  500\n",
      "€  |  NOUN  |  €\n",
      "to  |  ADP  |  to\n",
      "Steve  |  PROPN  |  Steve\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, ' | ', token.pos_, ' | ', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a217c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Tesla Inc aquired Twitter for a hooping $45 billion situated in the USA'\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8810e3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla  |  PROPN  |  Tesla\n",
      "Inc  |  PROPN  |  Inc\n",
      "aquired  |  VERB  |  aquire\n",
      "Twitter  |  PROPN  |  Twitter\n",
      "for  |  ADP  |  for\n",
      "a  |  DET  |  a\n",
      "hooping  |  VERB  |  hoop\n",
      "$  |  SYM  |  $\n",
      "45  |  NUM  |  45\n",
      "billion  |  NUM  |  billion\n",
      "situated  |  VERB  |  situate\n",
      "in  |  ADP  |  in\n",
      "the  |  DET  |  the\n",
      "USA  |  PROPN  |  USA\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, ' | ', token.pos_, ' | ', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c841e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc ORG  |  Companies, agencies, institutions, etc.\n",
      "Twitter ORG  |  Companies, agencies, institutions, etc.\n",
      "$45 billion MONEY  |  Monetary values, including unit\n",
      "USA GPE  |  Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "for token in doc.ents:\n",
    "    print(token.text, token.label_, ' | ', spacy.explain(token.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "921c7de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " aquired \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Twitter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for a hooping \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $45 billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " situated in the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    USA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ca8af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
